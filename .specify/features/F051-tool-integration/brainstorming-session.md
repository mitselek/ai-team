# Issue #51: Integrate Filesystem Tools into Agent Execution - Brainstorming Session

**Date:** November 15, 2025  
**Participants:** User (michelek), AI Assistant  
**Session Type:** Structured brainstorming following brainstorm.prompt.md workflow  
**Status:** Complete - Ready for sub-issue creation

---

## Executive Summary

This brainstorming session explored the architectural requirements for integrating MCP filesystem tools into the agent execution loop. We established a clear, provider-agnostic design that maintains MCP as the canonical standard while translating dynamically per LLM provider. The design emphasizes simplicity, extensibility, and alignment with industry-proven patterns.

**Key Outcome:** Clear architectural design ready for implementation in 4 phases.

---

## Problem Exploration (Phase 1: What?)

### What Exists Now?

**Current Architecture:**

```text
processor.ts: processTask(agent, task)
  ‚Üì
generateCompletion(prompt, {agentId})
  ‚Üì
Provider functions (anthropic/openai/google)
  ‚Üì
LLM API calls (NO tools parameter)
```

**Gap Identified:**

- No tools passed to LLM
- No tool use response handling
- No connection between orchestrator tool registry and processor

**Existing Infrastructure:**

- ‚úÖ MCPFileServer with 5 tools (read_file, write_file, delete_file, list_files, get_file_info)
- ‚úÖ ToolRegistry with executeTool() method
- ‚úÖ Security validation (identity, permissions, audit logging)
- ‚úÖ FilesystemService with CRUD operations
- ‚úÖ 100% security test coverage (50/50 passing)

### What's the Goal?

Enable agents to autonomously use filesystem tools during task processing:

1. LLM requests tool execution based on conversation context
2. System validates, executes, and returns results
3. LLM incorporates results into final response
4. Foundation for adding more MCP tools later (GitHub, Slack, etc.)

### What Constraints Exist?

**Technical:**

- Multiple LLM providers (Anthropic, OpenAI, Google) with different tool formats
- MCP protocol as existing standard
- Security requirements (identity validation, permissions, audit)
- Token budget limits per agent
- Context window limits

**Architectural:**

- Must maintain provider-agnostic design
- Must align with existing patterns (agent initialization, task processing)
- Must support future MCP tool additions
- Must be testable and maintainable

---

## Requirements Definition (Phase 2: Must Do/Not Do)

### Core Requirements

#### R1: Tool Triggering

**Decision:** LLM has full autonomy to decide when filesystem tools are needed  
**Rationale:** Tool decisions come from analyzing conversation context (chat, tasks, user requests)  
**Constraints:** System validates but doesn't restrict LLM's tool selection

#### R2: Tool Parameters

**Decision:** LLM provides tool name, arguments, and agentId  
**Format:** `{name: "read_file", arguments: {path: "/workspace/agents/marcus/notes.md", agentId: "agent-marcus"}}`  
**Validation:** agentId in parameters must match execution context (prevents impersonation)

#### R3: Validation Chain

**Sequence:**

1. ‚úì agentId matches execution context (orchestrator.ts - already implemented)
2. ‚úì tool exists in org config (NEW)
3. ‚úì tool not in team's blacklist (NEW)
4. ‚úì tool not in agent's blacklist (NEW)
5. ‚úì file permissions valid (already implemented)

**Error Handling:** All validation failures return descriptive errors to LLM

#### R4: Tool Availability

**Decision:** All agents get all org-defined tools by default  
**Configuration:**

- Org config lists available tools (e.g., 5 filesystem tools)
- Team optional blacklist: `toolBlacklist: string[]`
- Agent optional blacklist: `toolBlacklist: string[]`
- Blacklists merge (agent inherits team restrictions + adds own)

**Security:** Workspace isolation and permissions control actual access

#### R5: Error Transparency

**Decision:** All errors go back to LLM in conversation  
**Format:** `"Tool 'delete_file' restricted for your role"` or `"File not found at path X"`  
**Rationale:** LLM can try alternative approaches, explain to user, or request different permissions

#### R6: Format Standards

**Decision:** MCP format is canonical (Single Source of Truth)  
**Translation:** Dynamic per-provider translation at API boundary  
**Research Reference:** Based on "MCP Filesystem Tools for LLMs.md" - Section III.A standard pattern

**MCP Tool Format:**

```json
{
  "name": "read_file",
  "description": "Read file content from agent/team workspace",
  "inputSchema": {
    "type": "object",
    "properties": {...},
    "required": [...]
  }
}
```

**Provider Translations:**

- Anthropic: `inputSchema` ‚Üí `input_schema`
- OpenAI: `inputSchema` ‚Üí `parameters`
- Gemini: `inputSchema` ‚Üí `parameters` (nested in `functionDeclaration`)

#### R7: Tool Result Handling

**Decision:** Extract and simplify (Phase 1: simple, extensible for smart summarization)  
**Phase 1:** Extract `MCPToolResult.content[0].text` and send as-is  
**Future:** Add smart summarization when real-world problems with large results emerge  
**Format per provider:**

- Anthropic: `{role: "tool", content: [{type: "tool_result", tool_call_id: "...", content: "..."}]}`
- OpenAI: `{role: "tool", tool_call_id: "...", name: "...", content: "..."}`
- Gemini: `{role: "function", parts: [{functionResponse: {name: "...", response: {...}}}]}`

#### R8: Multi-Turn Flow

**Decision:** Iterative conversation loop until LLM provides final response  
**Flow:**

```text
LLM requests tool ‚Üí Execute ‚Üí Return result to LLM ‚Üí
LLM sees result, decides next action (another tool or final answer) ‚Üí
Loop continues until LLM provides final response
```

#### R9: Loop Protection

**Decision:** Max 20 tool calls per task  
**When Reached:** System message to LLM: "Tool call limit reached (20/20). Please provide your best answer based on information gathered so far."  
**Rationale:** Prevents infinite loops while allowing complex multi-file tasks  
**Scope:** Per task (counter resets for each new task)

**‚ö†Ô∏è NAGGING CONCERN:** This limit feels arbitrary. Need separate brainstorming session to explore:

- Is 20 the right number?
- Should it be configurable per agent/team/org?
- Should we have different limits for different tool types?
- Should we track tool call patterns and adjust dynamically?
- Are there better loop detection mechanisms than simple count?

**Recommendation:** Create follow-up issue for dedicated brainstorming on loop protection mechanisms.

### Must Not Do

- ‚ùå Don't modify MCP tool definitions from their source
- ‚ùå Don't pass raw MCP JSON results to LLM (extract/simplify first)
- ‚ùå Don't execute tools without identity validation
- ‚ùå Don't allow tool execution outside workspace boundaries
- ‚ùå Don't reload tools mid-task (wait for task completion or forced reload)
- ‚ùå Don't share conversation history across providers (each provider formats own history)

---

## Architecture Definition (Phase 3: How?)

### Component Responsibilities

#### 1. Organization Configuration (`data/organizations/{orgId}/org.json`)

**New Fields:**

```typescript
{
  // ... existing fields ...
  tools: MCPTool[]  // Available tools for this org
}
```

**Responsibilities:**

- Define available MCP tools (filesystem, future: GitHub, Slack, etc.)
- Single source of truth for tool definitions

#### 2. Team Configuration (`data/organizations/{orgId}/teams.json`)

**New Fields:**

```typescript
{
  // ... existing fields ...
  toolBlacklist?: string[]  // Optional: tools this team cannot use
}
```

#### 3. Agent Configuration (`data/organizations/{orgId}/agents.json`)

**New Fields:**

```typescript
{
  // ... existing fields ...
  toolBlacklist?: string[]  // Optional: tools this agent cannot use
}
```

#### 4. Agent Processor (`app/server/services/agent-engine/processor.ts`)

**New Responsibilities:**

- Load agent's available tools at initialization (org tools - team blacklist - agent blacklist)
- Maintain conversation history array
- Implement tool call loop with iteration limit
- Coordinate tool execution via orchestrator
- Add tool results to conversation history
- Handle loop limit enforcement

**Pseudocode:**

```typescript
async function processTask(agent: Agent, task: Task) {
  const availableTools = loadAgentTools(agent) // org tools - blacklists
  const messages = [{ role: 'user', content: task.description }]
  let iterations = 0
  const MAX_ITERATIONS = 20

  while (iterations < MAX_ITERATIONS) {
    const response = await generateCompletion(messages, {
      agentId: agent.id,
      tools: availableTools
    })

    const toolCalls = detectToolCalls(response) // provider-specific

    if (toolCalls.length === 0) {
      return response.text // Final answer
    }

    // Add assistant message with tool calls to history
    messages.push(formatAssistantMessage(response, toolCalls))

    // Execute each tool call
    for (const toolCall of toolCalls) {
      const result = await orchestrator.executeTool(toolCall.name, toolCall.arguments, {
        agentId: agent.id,
        organizationId: agent.organizationId,
        correlationId
      })
      messages.push(formatToolResult(toolCall, result)) // provider-specific
    }

    iterations++
  }

  // Limit reached - force final response
  messages.push({
    role: 'system',
    content:
      'Tool call limit reached (20/20). Please provide your best answer based on information gathered so far.'
  })
  const finalResponse = await generateCompletion(messages, { agentId: agent.id })
  return finalResponse.text
}
```

#### 5. LLM Service Layer (`app/server/services/llm/index.ts`)

**Changes:**

- Accept optional `tools` parameter in `LLMServiceOptions`
- Pass tools through to provider functions (no translation here)

**Interface:**

```typescript
interface LLMServiceOptions {
  // ... existing fields ...
  tools?: MCPTool[] // Optional MCP tools
}
```

#### 6. Provider Files (`app/server/services/llm/anthropic.ts`, `openai.ts`, `google.ts`)

**New Responsibilities:**

- Translate MCP tools ‚Üí provider-specific format
- Include translated tools in API call
- Detect tool calls in response (provider-specific parsing)
- Return standardized response with tool call information

**Anthropic Example:**

```typescript
export async function generateCompletionAnthropic(
  messages: Message[],
  options: LLMServiceOptions
): Promise<LLMResponse> {
  const tools = options.tools ? translateMCPToAnthropic(options.tools) : undefined

  const response = await client.messages.create({
    model: options.model,
    messages: translateMessagesToAnthropic(messages),
    tools: tools,
    max_tokens: options.maxTokens
  })

  const toolCalls = extractToolCalls(response) // Check for tool_use blocks

  return {
    content: response.content,
    toolCalls: toolCalls,
    provider: LLMProvider.ANTHROPIC
    // ... rest of response
  }
}

function translateMCPToAnthropic(mcpTools: MCPTool[]) {
  return mcpTools.map((tool) => ({
    name: tool.name,
    description: tool.description,
    input_schema: tool.inputSchema // Key difference: input_schema vs inputSchema
  }))
}

function extractToolCalls(response: AnthropicResponse) {
  const toolCalls = []
  for (const block of response.content) {
    if (block.type === 'tool_use') {
      toolCalls.push({
        id: block.id,
        name: block.name,
        arguments: block.input
      })
    }
  }
  return toolCalls
}
```

#### 7. Orchestrator (`app/server/services/orchestrator.ts`)

**New Validation:**

- Check tool exists in org config
- Check tool not in team blacklist
- Check tool not in agent blacklist
- (Existing: agentId validation, permissions validation)

**Enhanced executeTool():**

```typescript
async executeTool(
  name: string,
  params: Record<string, unknown>,
  context: ExecutionContext
): Promise<unknown> {
  // 1. Validate agentId (existing)
  validateAgentIdentity(params.agentId, context, name)

  // 2. Load agent and check tool availability (NEW)
  const agent = await dataLoader.loadAgent(context.agentId)
  const team = agent.teamId ? await dataLoader.loadTeam(agent.teamId) : null
  const org = await dataLoader.loadOrganization(context.organizationId)

  // Check tool exists in org
  if (!org.tools?.some(t => t.name === name)) {
    throw new Error(`Tool '${name}' not available in organization`)
  }

  // Check team blacklist
  if (team?.toolBlacklist?.includes(name)) {
    throw new PermissionError(
      `Tool '${name}' restricted for your team`,
      context.agentId, '', name, context.correlationId
    )
  }

  // Check agent blacklist
  if (agent.toolBlacklist?.includes(name)) {
    throw new PermissionError(
      `Tool '${name}' restricted for your role`,
      context.agentId, '', name, context.correlationId
    )
  }

  // 3. Check filesystem permissions (existing)
  if (FILESYSTEM_TOOLS.has(name) && permissionService) {
    const path = params.path as string
    const operation = mapToolToOperation(name)
    const hasAccess = permissionService.checkFileAccess(context.agentId, path, operation)
    if (!hasAccess) {
      throw new PermissionError(/* ... */)
    }
  }

  // 4. Execute tool
  const executor = tools.get(name)
  return await executor.execute(params, context)
}
```

#### 8. Type Definitions (`types/index.ts` and `app/server/services/llm/types.ts`)

**New/Updated Types:**

```typescript
// MCP Tool format (canonical)
interface MCPTool {
  name: string
  description: string
  inputSchema: {
    type: 'object'
    properties: Record<string, unknown>
    required?: string[]
  }
}

// LLM Response with tool calls
interface LLMResponse {
  content: string
  toolCalls?: ToolCall[] // NEW
  provider: LLMProvider
  model: string
  tokensUsed: TokenUsage
  finishReason: string
  metadata?: Record<string, unknown>
}

interface ToolCall {
  id: string
  name: string
  arguments: Record<string, unknown>
}

// Organization config
interface Organization {
  // ... existing fields ...
  tools?: MCPTool[] // NEW
}

// Team config
interface Team {
  // ... existing fields ...
  toolBlacklist?: string[] // NEW
}

// Agent config
interface Agent {
  // ... existing fields ...
  toolBlacklist?: string[] // NEW
}
```

### Data Flow

```text
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. INITIALIZATION PHASE                                          ‚îÇ
‚îÇ                                                                   ‚îÇ
‚îÇ Agent Load ‚Üí Load org.tools ‚Üí Filter team.toolBlacklist ‚Üí       ‚îÇ
‚îÇ              Filter agent.toolBlacklist ‚Üí availableTools         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. TASK PROCESSING LOOP (max 20 iterations)                     ‚îÇ
‚îÇ                                                                   ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ Processor builds conversation history + availableTools      ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                           ‚Üì                                       ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ LLM Service passes to provider (messages + MCP tools)       ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                           ‚Üì                                       ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ Provider (anthropic.ts/openai.ts/google.ts)                 ‚îÇ ‚îÇ
‚îÇ ‚îÇ   - Translates MCP tools ‚Üí provider format                  ‚îÇ ‚îÇ
‚îÇ ‚îÇ   - Translates messages ‚Üí provider format                   ‚îÇ ‚îÇ
‚îÇ ‚îÇ   - Calls LLM API                                            ‚îÇ ‚îÇ
‚îÇ ‚îÇ   - Detects tool calls in response                          ‚îÇ ‚îÇ
‚îÇ ‚îÇ   - Returns standardized LLMResponse with toolCalls         ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                           ‚Üì                                       ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ Processor checks for tool calls                             ‚îÇ ‚îÇ
‚îÇ ‚îÇ   If none: Return final response ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ ‚îÇ
‚îÇ ‚îÇ   If present: Continue to tool execution                    ‚îÇ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ ‚îÇ
‚îÇ                           ‚Üì                                      ‚îÇ ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ ‚îÇ
‚îÇ ‚îÇ For each tool call:                                         ‚îÇ‚îÇ ‚îÇ
‚îÇ ‚îÇ   Processor calls orchestrator.executeTool()                ‚îÇ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ ‚îÇ
‚îÇ                           ‚Üì                                      ‚îÇ ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ ‚îÇ
‚îÇ ‚îÇ Orchestrator validates:                                     ‚îÇ‚îÇ ‚îÇ
‚îÇ ‚îÇ   ‚úì agentId matches                                         ‚îÇ‚îÇ ‚îÇ
‚îÇ ‚îÇ   ‚úì tool in org.tools                                       ‚îÇ‚îÇ ‚îÇ
‚îÇ ‚îÇ   ‚úì tool not in team.toolBlacklist                          ‚îÇ‚îÇ ‚îÇ
‚îÇ ‚îÇ   ‚úì tool not in agent.toolBlacklist                         ‚îÇ‚îÇ ‚îÇ
‚îÇ ‚îÇ   ‚úì permissions valid                                       ‚îÇ‚îÇ ‚îÇ
‚îÇ ‚îÇ   If validation fails: throw error ‚Üí back to LLM            ‚îÇ‚îÇ ‚îÇ
‚îÇ ‚îÇ   If validation passes: execute tool                        ‚îÇ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ ‚îÇ
‚îÇ                           ‚Üì                                      ‚îÇ ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ ‚îÇ
‚îÇ ‚îÇ Tool executes (MCPFileServer ‚Üí FilesystemService)           ‚îÇ‚îÇ ‚îÇ
‚îÇ ‚îÇ   Returns MCPToolResult                                     ‚îÇ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ ‚îÇ
‚îÇ                           ‚Üì                                      ‚îÇ ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ ‚îÇ
‚îÇ ‚îÇ Processor extracts result:                                  ‚îÇ‚îÇ ‚îÇ
‚îÇ ‚îÇ   - Extract content[0].text from MCPToolResult              ‚îÇ‚îÇ ‚îÇ
‚îÇ ‚îÇ   - Format as tool result message (provider-specific)       ‚îÇ‚îÇ ‚îÇ
‚îÇ ‚îÇ   - Add to conversation history                             ‚îÇ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ ‚îÇ
‚îÇ                           ‚Üì                                      ‚îÇ ‚îÇ
‚îÇ                    Loop continues                                ‚îÇ ‚îÇ
‚îÇ                    (or exits if 20 iterations reached)           ‚îÇ ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. COMPLETION                                                    ‚îÇ
‚îÇ                                                                   ‚îÇ
‚îÇ Final response returned to user                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Provider-Specific Details

#### Tool Call Detection

**Anthropic:**

```typescript
// Response includes tool_use content blocks
response.stop_reason === 'tool_use'
response.content.forEach((block) => {
  if (block.type === 'tool_use') {
    toolCalls.push({
      id: block.id,
      name: block.name,
      arguments: block.input
    })
  }
})
```

**OpenAI:**

```typescript
// Response includes function_call items in output array
response.output.forEach((item) => {
  if (item.type === 'function_call') {
    toolCalls.push({
      id: item.call_id,
      name: item.name,
      arguments: JSON.parse(item.arguments)
    })
  }
})
```

**Gemini:**

```typescript
// Response includes functionCall in parts
response.candidates[0].content.parts.forEach((part) => {
  if (part.function_call) {
    toolCalls.push({
      id: generateId(), // Gemini doesn't provide call ID
      name: part.function_call.name,
      arguments: part.function_call.args
    })
  }
})
```

---

## Testing Strategy

### Unit Tests

**Tool Loading & Filtering:**

- ‚úì Load tools from org config
- ‚úì Apply team blacklist
- ‚úì Apply agent blacklist
- ‚úì Merge team + agent blacklists correctly
- ‚úì Handle missing toolBlacklist fields (optional)

**MCP to Provider Translation:**

- ‚úì Anthropic: inputSchema ‚Üí input_schema
- ‚úì OpenAI: inputSchema ‚Üí parameters
- ‚úì Gemini: inputSchema ‚Üí parameters (nested structure)
- ‚úì Preserve name and description
- ‚úì Handle empty tools array

**Tool Call Detection:**

- ‚úì Anthropic: Detect tool_use blocks
- ‚úì OpenAI: Detect function_call items
- ‚úì Gemini: Detect function_call in parts
- ‚úì Handle responses with no tool calls
- ‚úì Handle responses with multiple tool calls

**Tool Result Formatting:**

- ‚úì Extract text from MCPToolResult
- ‚úì Format for Anthropic (tool_result content block)
- ‚úì Format for OpenAI (tool role message)
- ‚úì Format for Gemini (functionResponse)
- ‚úì Handle isError flag from MCPToolResult

**Validation:**

- ‚úì agentId mismatch throws SecurityError
- ‚úì Tool not in org.tools throws error
- ‚úì Tool in team blacklist throws PermissionError with "restricted for your team"
- ‚úì Tool in agent blacklist throws PermissionError with "restricted for your role"
- ‚úì File permission denied throws PermissionError

**Loop Protection:**

- ‚úì Loop terminates after 20 iterations
- ‚úì System message sent when limit reached
- ‚úì Counter resets for new task

### Integration Tests

**End-to-End Flows (per provider):**

- ‚úì Single tool call flow (read file)
- ‚úì Multiple tool calls in sequence (list ‚Üí read ‚Üí write)
- ‚úì Tool call with error ‚Üí LLM receives error ‚Üí tries alternative
- ‚úì Tool call with permission denied ‚Üí LLM informed
- ‚úì Loop limit reached ‚Üí graceful degradation

**Multi-Provider:**

- ‚úì Same task works across all 3 providers
- ‚úì Tool call format differences handled correctly

**Security:**

- ‚úì Agent cannot impersonate another agent
- ‚úì Agent cannot use blacklisted tools
- ‚úì Agent cannot access files outside workspace
- ‚úì Audit logs created for all tool executions

**Configuration:**

- ‚úì Tools loaded at agent initialization
- ‚úì Changes to org config require agent reload
- ‚úì Blacklist changes require reload

### Coverage Target

**Industry Standard:** 80-90% code coverage  
**Critical Paths:** 100% coverage (validation, security, error handling)

---

## Implementation Phases

### Phase 1: Type Definitions & Configuration (2-3 hours)

**Files:**

- `types/index.ts` - Add MCPTool, update Organization/Team/Agent interfaces
- `app/server/services/llm/types.ts` - Add tools to LLMServiceOptions, toolCalls to LLMResponse
- `data/organizations/org-1/org.json` - Add tools array with 5 filesystem tools

**Tests:**

- Type compilation
- Schema validation

### Phase 2: Provider Translation Layer (4-5 hours)

**Files:**

- `app/server/services/llm/anthropic.ts` - Add tool translation, tool call detection
- `app/server/services/llm/openai.ts` - Add tool translation, tool call detection
- `app/server/services/llm/google.ts` - Add tool translation, tool call detection

**Tests:**

- Unit: MCP ‚Üí provider translation
- Unit: Tool call detection per provider
- Integration: Mock LLM responses with tool calls

### Phase 3: Orchestrator Validation (2-3 hours)

**Files:**

- `app/server/services/orchestrator.ts` - Add tool availability validation, blacklist checks
- `app/server/data/organizations.ts` - Add org config loading helpers

**Tests:**

- Unit: Tool availability validation
- Unit: Blacklist filtering (team, agent, merged)
- Integration: Validation errors propagate correctly

### Phase 4: Processor Integration & Loop (5-6 hours)

**Files:**

- `app/server/services/agent-engine/processor.ts` - Add tool loading, conversation history, loop logic
- `app/server/services/llm/index.ts` - Pass tools through to providers

**Tests:**

- Unit: Tool loading and filtering
- Unit: Loop iteration limit
- Integration: Full task processing with tools
- Integration: Multi-turn conversations
- Integration: Loop limit enforcement

**Total Estimated Time:** 13-17 hours

---

## Open Questions & Nagging Concerns

### üö® Primary Nagging Concern: Loop Protection

**The Issue:** The "max 20 tool calls per task" limit feels arbitrary and potentially problematic.

**Specific Concerns:**

1. **Is 20 the right number?**
   - Some legitimate tasks might need more (e.g., "analyze all team member notes" with 25 agents)
   - Some infinite loops might be caught earlier (e.g., same tool failing 3 times in a row)

2. **Should it be configurable?**
   - Per organization (different orgs have different complexity needs)
   - Per team (development team vs. HR team)
   - Per agent (senior agents get more iterations?)
   - Per task priority/type

3. **Are there better detection mechanisms?**
   - Pattern detection: Same tool called 3+ times with same parameters = loop
   - Success rate: If 5 consecutive tool calls fail, suggest alternative approach
   - Resource-based: Track token usage instead of call count
   - Time-based: Max 5 minutes of tool execution time
   - Adaptive: Learn from successful task patterns

4. **Should different tools have different limits?**
   - Read-only tools (read_file, list_files, get_file_info) - unlimited?
   - Write tools (write_file, delete_file) - more restrictive?
   - External API tools (future: GitHub, Slack) - even more restrictive?

5. **What about parallelization?**
   - If LLM requests 5 tools at once, does that count as 1 or 5?
   - OpenAI and Gemini support parallel function calling
   - Should parallel calls count differently?

**Recommendation:**

- **For Issue #51 (MVP):** Implement simple 20-call limit as baseline
- **Create Follow-Up Issue:** "Brainstorm: Intelligent Loop Protection Mechanisms"
  - Dedicated brainstorming session
  - Research industry patterns
  - Prototype different approaches
  - Gather real-world usage data from Issue #51 implementation

**Action Item:** Create Issue #XX after Issue #51 sub-issues are defined.

### Minor Questions (Can be addressed during implementation)

1. **Tool reload mechanisms:**
   - How to signal agent for graceful reload?
   - UI/API for force reload at org/team/agent levels?
   - ‚Üí Can be part of agent management features (separate from #51)

2. **Audit logging for tool calls:**
   - Should we log every tool request from LLM (even before validation)?
   - Should we log LLM's reasoning for tool selection?
   - ‚Üí Current audit logging sufficient for MVP, enhance later if needed

3. **Token budget interaction:**
   - How do tool definitions impact token budget?
   - Should tool results count against agent's token budget?
   - ‚Üí Monitor during implementation, adjust if budget issues arise

---

## Success Criteria

### Functional Success

- ‚úÖ Agent can successfully use filesystem tools during task execution
- ‚úÖ Tool calls work across all 3 LLM providers (Anthropic, OpenAI, Google)
- ‚úÖ Security validation prevents unauthorized tool access
- ‚úÖ Errors propagate correctly to LLM for alternative approaches
- ‚úÖ Multi-turn tool conversations complete successfully
- ‚úÖ Loop protection prevents infinite iterations

### Quality Success

- ‚úÖ 80-90% code coverage overall
- ‚úÖ 100% coverage on security-critical paths
- ‚úÖ All existing tests continue to pass (537/550+)
- ‚úÖ No regression in agent task processing
- ‚úÖ TypeScript strict mode clean

### Performance Success

- ‚úÖ Tool loading doesn't significantly slow agent initialization (<100ms overhead)
- ‚úÖ Tool translation adds minimal latency (<10ms per LLM call)
- ‚úÖ Multi-turn tool conversations complete in reasonable time

### Architectural Success

- ‚úÖ MCP remains canonical standard (no vendor lock-in)
- ‚úÖ Provider-specific code isolated to provider files
- ‚úÖ Easy to add new MCP tools in future
- ‚úÖ Easy to add new LLM providers
- ‚úÖ Clear separation of concerns

---

## References

1. **MCP Filesystem Tools for LLMs** (`docs/MCP Filesystem Tools for LLMs.md`)
   - Comprehensive research on MCP integration patterns
   - Provider format comparison tables
   - Best practices from production systems

2. **Existing Issues:**
   - Issue #39: Parent issue for filesystem access system
   - Issues #40-#49: Individual filesystem components (complete)
   - Issue #50: Security test fixes (complete)
   - Issue #51: This implementation (ready to break into sub-issues)

3. **Existing Code:**
   - `app/server/services/mcp/file-server.ts` - MCPFileServer implementation
   - `app/server/services/orchestrator.ts` - Tool registry and validation
   - `app/server/services/persistence/*` - Filesystem services
   - `app/server/services/agent-engine/processor.ts` - Current task processing
   - `app/server/services/llm/*` - LLM provider implementations

4. **Test Suites:**
   - `tests/security/filesystem-security.spec.ts` - 50 security tests (100% passing)
   - `tests/services/mcp/file-server.spec.ts` - MCP server tests
   - `tests/services/orchestrator-security.spec.ts` - Security validation tests

---

## Next Steps

1. **Create Sub-Issues for Issue #51** (4 sub-issues aligned with implementation phases)
   - Issue #51.1: Type Definitions & Configuration
   - Issue #51.2: Provider Translation Layer
   - Issue #51.3: Orchestrator Validation
   - Issue #51.4: Processor Integration & Loop

2. **Create Follow-Up Issue: Loop Protection Research**
   - Title: "Brainstorm: Intelligent Loop Protection Mechanisms for Tool Execution"
   - Reference this document's nagging concerns section
   - Schedule separate brainstorming session
   - Gather real-world data from Issue #51 usage first

3. **Begin Implementation** (sequential phases with validation at each step)

---

## Session Metadata

**Brainstorming Duration:** ~2 hours  
**Questions Explored:** 15+  
**Key Decisions Made:** 12  
**Architecture Diagrams:** 1 (data flow)  
**Research Documents Referenced:** 1 (MCP Filesystem Tools for LLMs)  
**Files to be Modified:** 10+  
**Tests to be Created:** 30+  
**Estimated Implementation Time:** 13-17 hours (4 phases)

**Session Quality:** ‚úÖ Complete architectural understanding achieved  
**Confidence Level:** High - Ready for implementation  
**Risks Identified:** 1 (loop protection mechanism - requires follow-up)
